{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data contains sequencing result from both Nextseq PE150 and Novaseq SE75 runs.\n",
    "\n",
    "Among them, \n",
    "    1. S6, S18, S19, S20 are the mock sample with 4 bacterial species, with only Nextseq sequencing results.\n",
    "    2. The others are stool samples\n",
    "        44-14: S14, with both Nextseq and Novaseq results\n",
    "        44-52: S31, S32, S34, with only Nextseq sequencing results\n",
    "        44-150: S5, S7, S15, S27, with both Nextseq and Novaseq results\n",
    "        44-111: S8, S9, with both Nextseq and Novaseq results\n",
    "        44-171: S10, with both Nextseq and Novaseq results\n",
    "        44-172: S11, S12, with both Nextseq and Novaseq results\n",
    "        44-224: S33, S35, with only Nextseq sequencing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "base_dirt = \"./sequencing_microbeseq/\"\n",
    "trimmed_dir_base = base_dirt + \"trimmed/\"\n",
    "R1R2_filtered_dir_base = base_dirt + \"filtered_selected/\"\n",
    "output_dirt = base_dirt + \"filtered/\"\n",
    "barcode_dirt = \"./bc1andbc2.xlsx\" # the folder with barcode 1 and barcode 2 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcode Information\n",
    "bc1_number = 96\n",
    "bc2_number = 384\n",
    "barcode_temp = pd.read_excel(barcode_dirt)\n",
    "bc2_temp = barcode_temp['bc2'].values\n",
    "bc2 = []\n",
    "for i in range(bc2_number):\n",
    "    bc2 += [str(bc2_temp[i][31:39])]\n",
    "bc1_temp = barcode_temp['bc1'].values\n",
    "bc1 = []\n",
    "for i in range(bc1_number):\n",
    "    loc = bc1_temp[i].find(\"AGATCGGAAGAGCGTCGTGTAGGGAAAGAG\")\n",
    "    bc1 += [str(bc1_temp[i][23:loc-1])]\n",
    "\n",
    "number_barcode = bc1_number * bc2_number \n",
    "while True:\n",
    "    i = 0\n",
    "    while True:\n",
    "        sample_ID_multiplier =  10**(i)\n",
    "        if sample_ID_multiplier > number_barcode:\n",
    "            break\n",
    "        i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function count_match\n",
    "# input: two strings a and b with same length\n",
    "# output: number of matches between strings a and b\n",
    "def count_match(a, b):\n",
    "    if len(a) != len(b):\n",
    "        return 0\n",
    "    n = len(a)\n",
    "    match_number = 0\n",
    "    for i in range(n):\n",
    "        if a[i] == b[i]:\n",
    "            match_number += 1\n",
    "    return match_number\n",
    "\n",
    "# returns reverse complement of a sequence\n",
    "def reverseComplement(s):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    t = ''\n",
    "    for base in s:\n",
    "        t = complement[base] + t\n",
    "    return t\n",
    "\n",
    "# returns the hamming distance fo two strings\n",
    "def hamdist(str1, str2):\n",
    "    diffs = 0\n",
    "    for ch1, ch2 in zip(str1, str2):\n",
    "        if ch1 != ch2:\n",
    "            diffs += 1\n",
    "    return diffs\n",
    "    \n",
    "# returns the closest hamming distance of the starting location of 2 sequences, if larger than 5, return -1\n",
    "def find_W1_loc(read, W1 = \"GAGTGATTGCTTGTGACGCCTT\", threshold = 5):\n",
    "    length_W1 = len(W1)\n",
    "    start_loc = 8\n",
    "    tests = 4\n",
    "    closest_loc = start_loc\n",
    "    diff = length_W1\n",
    "    for i in range(tests):\n",
    "        diff_temp = hamdist(read[start_loc + i:start_loc + i + length_W1], W1) \n",
    "        if diff > diff_temp:\n",
    "            closest_loc = i + start_loc\n",
    "            diff = diff_temp\n",
    "        #if hamming diatance less then threshold, then the location is correct and returned\n",
    "        if diff < threshold:\n",
    "            return closest_loc\n",
    "    return 0\n",
    "\n",
    "def closest_index(str1, ref_list, mismatch_allow = 1):\n",
    "    closest_index_list = []\n",
    "    closest_ham_dist = len(str1)\n",
    "    for i in range(len(ref_list)):\n",
    "        ham_dist_temp = hamdist(str1, ref_list[i])\n",
    "        if ham_dist_temp < closest_ham_dist:# if a closer element if found, initialize closest_index_list and closest_ham_dist\n",
    "            closest_ham_dist = ham_dist_temp\n",
    "            closest_index_list = [i]\n",
    "        elif ham_dist_temp == closest_ham_dist:# if it's the same length, add it to length list\n",
    "            closest_index_list += [i]\n",
    "    if closest_ham_dist <= mismatch_allow:\n",
    "        return closest_index_list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### First process Nextseq result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with input read file, output each sorted file, each output file is a barcode/single cell\n",
    "# All input fastq files should have this format\n",
    "#     S*_R1.fastq, and S*_R2.fastq\n",
    "def fastq_filter(Sample_index, input_dirt, output_dirt, R1_file_ending = \"_R1.fastq\", R2_file_ending = \"_R2.fastq\"):\n",
    "    sample_number_ID = Sample_index*sample_ID_multiplier \n",
    "    # this is to directly take input read files, check structre, then sort reads according to their barcode number\n",
    "\n",
    "    R1_ori_dir = input_dirt+ \"S\"+str(Sample_index) + R1_file_ending\n",
    "    R2_ori_dir = input_dirt+ \"S\"+str(Sample_index) + R2_file_ending\n",
    "    # This is to creat empty file which will be used to store reads later\n",
    "    # Both R1 and R2 files are output into the same folder, this will be easier for later adapter trim\n",
    "    for i in range(number_barcode):\n",
    "        dirct = output_dirt + str(i+sample_number_ID) + '_R1.fastq'\n",
    "        foutput1 = open(dirct, 'w')        \n",
    "        foutput1.close()\n",
    "        dirct = output_dirt + str(i+sample_number_ID) + '_R2.fastq'\n",
    "        foutput1 = open(dirct, 'w')        \n",
    "        foutput1.close()\n",
    "    hit_map = [] # label if the read pass stru and barcode check, -1 means no pass\n",
    "    # initialize\n",
    "    loc_list_temp = []\n",
    "    read_list_temp = []\n",
    "    hold_list_temp = []\n",
    "    quality_list_temp = []\n",
    "    for i in range(number_barcode): \n",
    "        # each i is a brcode, and this element in list stores corresponding information\n",
    "        loc_list_temp += [[]]\n",
    "        read_list_temp += [[]]\n",
    "        hold_list_temp += [[]]\n",
    "        quality_list_temp += [[]]\n",
    "    #sample_read_count = [0]*(samples+1) # store read number for each sample, 0 for no match (bad), others for each sample\n",
    "    test_flag = 0 # used to count how many reads processed\n",
    "    indicator_W1fail = 0\n",
    "    indicator_BC1fail = 0\n",
    "    indicator_BC2fail = 0\n",
    "    indicator_BC1_mismatch_allowed = 0\n",
    "    indicator_BC2_mismatch_allowed = 0\n",
    "    indicator_R1_short = 0\n",
    "    storage_read_number = 1000000 \n",
    "    # how many reads to take before output (this is a balance between I/O speed and RAM use)\n",
    "    BC2_fail_dist = []\n",
    "    with open(R1_ori_dir) as finput:\n",
    "        while True:            \n",
    "            flag = -1 # flag which sample the read is, -1 means not a good read\n",
    "            test_flag += 1 # count read number\n",
    "            line_loc = finput.readline()\n",
    "            line_read = finput.readline()\n",
    "            line_hold = finput.readline()\n",
    "            line_quality = finput.readline()\n",
    "            if len (line_read) == 0:\n",
    "                break\n",
    "            if len (line_read) <= 80: # if too short, no need to keep this read\n",
    "                # It's important to use 80 instead of 41 here, \n",
    "                # as part of Read1 is going to be written in the file\n",
    "                # if Read 1 is too short, output would be empty, leading to error\n",
    "                #sample_read_count[0] += 1\n",
    "                hit_map += [-1]\n",
    "                indicator_R1_short += 1\n",
    "                print sample_number_ID, \"length less then 80\"\n",
    "                continue\n",
    "            loc = find_W1_loc(line_read)\n",
    "            if loc:\n",
    "                bc1_temp = reverseComplement(line_read[:loc])                \n",
    "                bc2_temp = reverseComplement(line_read[loc+22:loc+30])                \n",
    "                if bc1_temp in bc1: \n",
    "                    index1_temp = bc1.index(bc1_temp)\n",
    "                    if bc2_temp in bc2:\n",
    "                        index2_temp = bc2.index(bc2_temp)\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                        loc_list_temp[index_temp].append(line_loc)\n",
    "                        read_list_temp[index_temp].append(line_read[loc+63:])\n",
    "                        hold_list_temp[index_temp].append(line_hold)\n",
    "                        quality_list_temp[index_temp].append(line_quality[loc+63:])  \n",
    "                    elif len(closest_index(bc2_temp, bc2)) == 1:\n",
    "                        indicator_BC2_mismatch_allowed += 1\n",
    "                        index2_temp = closest_index(bc2_temp, bc2)[0]\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                        loc_list_temp[index_temp].append(line_loc)\n",
    "                        read_list_temp[index_temp].append(line_read[loc+63:])\n",
    "                        hold_list_temp[index_temp].append(line_hold)\n",
    "                        quality_list_temp[index_temp].append(line_quality[loc+63:])  \n",
    "                    else:\n",
    "                        indicator_BC2fail += 1\n",
    "                        index2_temp = -1\n",
    "                elif len(closest_index(bc1_temp, bc1)) == 1:\n",
    "                    indicator_BC1_mismatch_allowed += 1\n",
    "                    index1_temp = closest_index(bc1_temp, bc1)[0]\n",
    "                    if bc2_temp in bc2:\n",
    "                        index2_temp = bc2.index(bc2_temp)\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                        loc_list_temp[index_temp].append(line_loc)\n",
    "                        read_list_temp[index_temp].append(line_read[loc+63:])\n",
    "                        hold_list_temp[index_temp].append(line_hold)\n",
    "                        quality_list_temp[index_temp].append(line_quality[loc+63:])  \n",
    "                    elif len(closest_index(bc2_temp, bc2)) == 1:\n",
    "                        indicator_BC2_mismatch_allowed += 1\n",
    "                        index2_temp = closest_index(bc2_temp, bc2)[0]\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                        loc_list_temp[index_temp].append(line_loc)\n",
    "                        read_list_temp[index_temp].append(line_read[loc+63:])\n",
    "                        hold_list_temp[index_temp].append(line_hold)\n",
    "                        quality_list_temp[index_temp].append(line_quality[loc+63:])  \n",
    "                    else:\n",
    "                        indicator_BC2fail += 1\n",
    "                        index2_temp = -1\n",
    "                else: \n",
    "                    indicator_BC1fail += 1\n",
    "            else:\n",
    "                indicator_W1fail += 1                \n",
    "            hit_map += [flag]                          \n",
    "            if test_flag % storage_read_number == 0:\n",
    "                for i in range(number_barcode): # i is the number of barcode\n",
    "                    dirct = output_dirt + str(i+sample_number_ID) + '_R1.fastq'\n",
    "                    with open(dirct, 'a') as foutput1:\n",
    "                        for j in range(len(loc_list_temp[i])):\n",
    "                            foutput1.write(loc_list_temp[i][j])\n",
    "                            foutput1.write(read_list_temp[i][j])                       \n",
    "                            foutput1.write(hold_list_temp[i][j])\n",
    "                            foutput1.write(quality_list_temp[i][j])\n",
    "                    foutput1.close()  \n",
    "                # initialize\n",
    "                loc_list_temp = []\n",
    "                read_list_temp = []\n",
    "                hold_list_temp = []\n",
    "                quality_list_temp = []\n",
    "                for i in range(number_barcode):\n",
    "                    loc_list_temp += [[]]\n",
    "                    read_list_temp += [[]]\n",
    "                    hold_list_temp += [[]]\n",
    "                    quality_list_temp += [[]]              \n",
    "    finput.close()\n",
    "    # write out remaining data\n",
    "    for i in range(number_barcode):\n",
    "        dirct = output_dirt + str(i+sample_number_ID) + '_R1.fastq'\n",
    "        with open(dirct, 'a') as foutput1:\n",
    "            for j in range(len(loc_list_temp[i])):\n",
    "                foutput1.write(loc_list_temp[i][j])\n",
    "                foutput1.write(read_list_temp[i][j])                       \n",
    "                foutput1.write(hold_list_temp[i][j])\n",
    "                foutput1.write(quality_list_temp[i][j])\n",
    "        foutput1.close()  \n",
    "    print \"Sample number is:\", Sample_index\n",
    "    print \"Total read number for this sample is:\", len(hit_map)\n",
    "    print 'Total read pass structure check is {}, BC1 fail is {}, BC1 one mismatch is {},\\\n",
    "    W1 fail is {}, BC2 fail is {}, BC2 one mismatch is {}.\\n'\\\n",
    "    .format(len(hit_map) - indicator_BC1fail-indicator_W1fail-indicator_BC2fail-indicator_R1_short,\\\n",
    "            indicator_BC1fail, indicator_BC1_mismatch_allowed, indicator_W1fail, \\\n",
    "            indicator_BC2fail, indicator_BC2_mismatch_allowed)\n",
    "\n",
    "    # Based on the labeling of each read, take and sort Read 2 according to barcodes\n",
    "\n",
    "    # initialize\n",
    "    loc_list_temp = []\n",
    "    read_list_temp = []\n",
    "    hold_list_temp = []\n",
    "    quality_list_temp = []\n",
    "    for i in range(number_barcode):\n",
    "        loc_list_temp += [[]]\n",
    "        read_list_temp += [[]]\n",
    "        hold_list_temp += [[]]\n",
    "        quality_list_temp += [[]]\n",
    "            \n",
    "    test_flag = 0\n",
    "    with open(R2_ori_dir) as finput:\n",
    "        for k in range(len(hit_map)):\n",
    "            test_flag += 1\n",
    "            line_loc = finput.readline()\n",
    "            line_read = finput.readline()\n",
    "            line_hold = finput.readline()\n",
    "            line_quality = finput.readline()\n",
    "            index_temp = hit_map[k]\n",
    "            if hit_map[k] != -1:\n",
    "                loc_list_temp[index_temp].append(line_loc)\n",
    "                read_list_temp[index_temp].append(line_read)\n",
    "                hold_list_temp[index_temp].append(line_hold)\n",
    "                quality_list_temp[index_temp].append(line_quality) \n",
    "            if test_flag % storage_read_number == 0:\n",
    "                for i in range(number_barcode):\n",
    "                    dirct = output_dirt + str(i+sample_number_ID) + '_R2.fastq'\n",
    "                    with open(dirct, 'a') as foutput1:\n",
    "                        for j in range(len(loc_list_temp[i])):\n",
    "                            foutput1.write(loc_list_temp[i][j])\n",
    "                            foutput1.write(read_list_temp[i][j])                       \n",
    "                            foutput1.write(hold_list_temp[i][j])\n",
    "                            foutput1.write(quality_list_temp[i][j])\n",
    "                    foutput1.close()\n",
    "                # initialize\n",
    "                loc_list_temp = []\n",
    "                read_list_temp = []\n",
    "                hold_list_temp = []\n",
    "                quality_list_temp = []\n",
    "                for i in range(number_barcode):\n",
    "                    loc_list_temp += [[]]\n",
    "                    read_list_temp += [[]]\n",
    "                    hold_list_temp += [[]]\n",
    "                    quality_list_temp += [[]]   \n",
    "    # write in remaining data\n",
    "    for i in range(number_barcode):\n",
    "        dirct = output_dirt + str(i+sample_number_ID) + '_R2.fastq'\n",
    "        with open(dirct, 'a') as foutput1:\n",
    "            for j in range(len(loc_list_temp[i])):\n",
    "                foutput1.write(loc_list_temp[i][j])            \n",
    "                foutput1.write(read_list_temp[i][j])                       \n",
    "                foutput1.write(hold_list_temp[i][j])\n",
    "                foutput1.write(quality_list_temp[i][j])\n",
    "        foutput1.close()  \n",
    "    finput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(R1R2_filtered_dir_base):\n",
    "    os.mkdir(R1R2_filtered_dir_base)\n",
    "if not os.path.isdir(output_dirt):\n",
    "    os.mkdir(output_dirt)\n",
    "if not os.path.isdir(trimmed_dir_base):\n",
    "    os.mkdir(trimmed_dir_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_list_total = [18, 19, 20, 6]\n",
    "for Sample_index in sample_list_total:\n",
    "    fastq_filter(Sample_index, base_dirt + \"original_files/\", output_dirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_list_total = [5, 7, 8, 9, 10, 11, 12, 14, 15, 27]\n",
    "for Sample_index in sample_list_total:\n",
    "    fastq_filter(Sample_index, base_dirt + \"original_files/\", output_dirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_list_total = [31, 32, 33, 34, 35]\n",
    "for Sample_index in sample_list_total:\n",
    "    fastq_filter(Sample_index, base_dirt + \"original_files/\", output_dirt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Then process Novaseq result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with input read file, output each sorted file, each output file is a barcode/single cell\n",
    "# All input fastq files should have this format\n",
    "# S*_R1.fastq, and S*_R2.fastq\n",
    "def fastq_filter_SE(Sample_index, input_dirt, output_dirt, R1_file_ending = \"_R1.fastq\", R2_file_ending = \"_R2.fastq\"):\n",
    "    sample_number_ID = Sample_index*sample_ID_multiplier \n",
    "    # this is to directly take input read files, check structre, then sort reads according to their barcode number\n",
    "\n",
    "    R1_ori_dir = input_dirt+ \"S\"+str(Sample_index) + R1_file_ending\n",
    "    R2_ori_dir = input_dirt+ \"S\"+str(Sample_index) + R2_file_ending\n",
    "    # This is to creat empty file which will be used to store reads later\n",
    "    # Both R1 and R2 files are output into the same folder, this will be easier for later adapter trim\n",
    "    for i in range(number_barcode):\n",
    "        dirct = output_dirt + str(i+sample_number_ID) + '_R2_nova.fastq'\n",
    "        foutput1 = open(dirct, 'w')        \n",
    "        foutput1.close()\n",
    "    hit_map = [] # label if the read pass stru and barcode check, -1 means no pass\n",
    "    # initialize\n",
    "    loc_list_temp = []\n",
    "    read_list_temp = []\n",
    "    hold_list_temp = []\n",
    "    quality_list_temp = []\n",
    "    for i in range(number_barcode): \n",
    "        # each i is a brcode, and this element in list stores corresponding information\n",
    "        loc_list_temp += [[]]\n",
    "        read_list_temp += [[]]\n",
    "        hold_list_temp += [[]]\n",
    "        quality_list_temp += [[]]\n",
    "    #sample_read_count = [0]*(samples+1) # store read number for each sample, 0 for no match (bad), others for each sample\n",
    "    test_flag = 0 # used to count how many reads processed\n",
    "    indicator_W1fail = 0\n",
    "    indicator_BC1fail = 0\n",
    "    indicator_BC2fail = 0\n",
    "    indicator_BC1_mismatch_allowed = 0\n",
    "    indicator_BC2_mismatch_allowed = 0\n",
    "    indicator_R1_short = 0\n",
    "    storage_read_number = 1000000 \n",
    "    # how many reads to take before output (this is a balance between I/O speed and RAM use)\n",
    "    BC2_fail_dist = []\n",
    "    with open(R1_ori_dir) as finput:\n",
    "        while True:            \n",
    "            flag = -1 # flag which sample the read is, -1 means not a good read\n",
    "            test_flag += 1 # count read number\n",
    "            line_loc = finput.readline()\n",
    "            line_read = finput.readline()\n",
    "            line_hold = finput.readline()\n",
    "            line_quality = finput.readline()\n",
    "            if len (line_read) == 0:\n",
    "                break\n",
    "            if len (line_read) <= 41: # if too short, no need to keep this read\n",
    "                #sample_read_count[0] += 1\n",
    "                hit_map += [-1]\n",
    "                indicator_R1_short += 1\n",
    "                print sample_number_ID, \"length less then 41\"\n",
    "                continue\n",
    "            loc = find_W1_loc(line_read)\n",
    "            if loc:\n",
    "                bc1_temp = reverseComplement(line_read[:loc])                \n",
    "                bc2_temp = reverseComplement(line_read[loc+22:loc+30])                \n",
    "                if bc1_temp in bc1: \n",
    "                    index1_temp = bc1.index(bc1_temp)\n",
    "                    if bc2_temp in bc2:\n",
    "                        index2_temp = bc2.index(bc2_temp)\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                    elif len(closest_index(bc2_temp, bc2)) == 1:\n",
    "                        indicator_BC2_mismatch_allowed += 1\n",
    "                        index2_temp = closest_index(bc2_temp, bc2)[0]\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                    else:\n",
    "                        indicator_BC2fail += 1\n",
    "                        index2_temp = -1\n",
    "                elif len(closest_index(bc1_temp, bc1)) == 1:\n",
    "                    indicator_BC1_mismatch_allowed += 1\n",
    "                    index1_temp = closest_index(bc1_temp, bc1)[0]\n",
    "                    if bc2_temp in bc2:\n",
    "                        index2_temp = bc2.index(bc2_temp)\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp\n",
    "                    elif len(closest_index(bc2_temp, bc2)) == 1:\n",
    "                        indicator_BC2_mismatch_allowed += 1\n",
    "                        index2_temp = closest_index(bc2_temp, bc2)[0]\n",
    "                        index_temp = index1_temp * bc2_number + index2_temp\n",
    "                        flag = index_temp \n",
    "                    else:\n",
    "                        indicator_BC2fail += 1\n",
    "                        index2_temp = -1\n",
    "                else: \n",
    "                    indicator_BC1fail += 1\n",
    "            else:\n",
    "                indicator_W1fail += 1                \n",
    "            hit_map += [flag]        \n",
    "    finput.close()\n",
    "    print \"Sample number is:\", Sample_index\n",
    "    print \"\\nTotal read number for this sample is:\", len(hit_map)\n",
    "    print 'Total read pass structure check is {}, BC1 fail is {}, BC1 one mismatch is {},\\\n",
    "    W1 fail is {}, BC2 fail is {}, BC2 one mismatch is {}.'\\\n",
    "    .format(len(hit_map) - indicator_BC1fail-indicator_W1fail-indicator_BC2fail-indicator_R1_short,\\\n",
    "            indicator_BC1fail, indicator_BC1_mismatch_allowed, indicator_W1fail, \\\n",
    "            indicator_BC2fail, indicator_BC2_mismatch_allowed)\n",
    "\n",
    "    # Based on the labeling of each read, take and sort Read 2 according to barcodes\n",
    "\n",
    "    # initialize\n",
    "    loc_list_temp = []\n",
    "    read_list_temp = []\n",
    "    hold_list_temp = []\n",
    "    quality_list_temp = []\n",
    "    for i in range(number_barcode):\n",
    "        loc_list_temp += [[]]\n",
    "        read_list_temp += [[]]\n",
    "        hold_list_temp += [[]]\n",
    "        quality_list_temp += [[]]\n",
    "            \n",
    "    test_flag = 0\n",
    "    with open(R2_ori_dir) as finput:\n",
    "        for k in range(len(hit_map)):\n",
    "            test_flag += 1\n",
    "            line_loc = finput.readline()\n",
    "            line_read = finput.readline()\n",
    "            line_hold = finput.readline()\n",
    "            line_quality = finput.readline()\n",
    "            index_temp = hit_map[k]\n",
    "            if hit_map[k] != -1:\n",
    "                loc_list_temp[index_temp].append(line_loc)\n",
    "                read_list_temp[index_temp].append(line_read)\n",
    "                hold_list_temp[index_temp].append(line_hold)\n",
    "                quality_list_temp[index_temp].append(line_quality) \n",
    "            if test_flag % storage_read_number == 0:\n",
    "                for i in range(number_barcode):\n",
    "                    dirct = output_dirt + str(i+sample_number_ID) + '_R2_nova.fastq'\n",
    "                    with open(dirct, 'a') as foutput1:\n",
    "                        for j in range(len(loc_list_temp[i])):\n",
    "                            foutput1.write(loc_list_temp[i][j])\n",
    "                            foutput1.write(read_list_temp[i][j])                       \n",
    "                            foutput1.write(hold_list_temp[i][j])\n",
    "                            foutput1.write(quality_list_temp[i][j])\n",
    "                    foutput1.close()\n",
    "                # initialize\n",
    "                loc_list_temp = []\n",
    "                read_list_temp = []\n",
    "                hold_list_temp = []\n",
    "                quality_list_temp = []\n",
    "                for i in range(number_barcode):\n",
    "                    loc_list_temp += [[]]\n",
    "                    read_list_temp += [[]]\n",
    "                    hold_list_temp += [[]]\n",
    "                    quality_list_temp += [[]]   \n",
    "    # write in remaining data\n",
    "    for i in range(number_barcode):\n",
    "        dirct = output_dirt + str(i+sample_number_ID) + '_R2_nova.fastq'\n",
    "        with open(dirct, 'a') as foutput1:\n",
    "            for j in range(len(loc_list_temp[i])):\n",
    "                foutput1.write(loc_list_temp[i][j])            \n",
    "                foutput1.write(read_list_temp[i][j])                       \n",
    "                foutput1.write(hold_list_temp[i][j])\n",
    "                foutput1.write(quality_list_temp[i][j])\n",
    "        foutput1.close()  \n",
    "    finput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirt_nova = \"./sequencing_microbeseq/original_files/Novaseq/\"\n",
    "trimmed_dir_base_nova = base_dirt + \"trimmed/\"\n",
    "R1R2_filtered_dir_base_nova = base_dirt + \"filtered_selected/\"\n",
    "output_dirt_nova = base_dirt + \"filtered/\"\n",
    "if not os.path.isdir(R1R2_filtered_dir_base_nova):\n",
    "    os.mkdir(R1R2_filtered_dir_base_nova)\n",
    "if not os.path.isdir(output_dirt_nova):\n",
    "    os.mkdir(output_dirt_nova)\n",
    "if not os.path.isdir(trimmed_dir_base_nova):\n",
    "    os.mkdir(trimmed_dir_base_nova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_list_total = [5, 7, 8, 9, 10, 11, 12, 14, 15, 27]\n",
    "for Sample_index in sample_list_total:\n",
    "    fastq_filter_SE(Sample_index, base_dirt_nova, output_dirt_nova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes input directory and returns read number counts of each \n",
    "# takes dirt and Sample_index\n",
    "# This is to read in the length of each and every file\n",
    "def read_number_count(Sample_index, input_dirt):    \n",
    "    sample_number_ID = Sample_index*sample_ID_multiplier\n",
    "    sort_read_counts = []\n",
    "    for i in range(number_barcode):\n",
    "        dirct = input_dirt + str(i+sample_number_ID) + '_R1.fastq'\n",
    "        reads_temp = 0\n",
    "        with open(dirct) as finput:\n",
    "            while True:\n",
    "                line_loc = finput.readline()\n",
    "                line_read = finput.readline()\n",
    "                line_hold = finput.readline()\n",
    "                line_quality = finput.readline()\n",
    "                if len (line_read) == 0:\n",
    "                    break\n",
    "                reads_temp += 1\n",
    "        finput.close()\n",
    "        sort_read_counts += [reads_temp]  \n",
    "    a_temp_df_read = pd.DataFrame({'barcode_list': range(sample_number_ID,sample_number_ID+number_barcode)}) \n",
    "    a_temp_df_read['read_number'] = sort_read_counts\n",
    "    a_temp_df_read.to_csv(base_dirt+'S'+str(Sample_index)+\"_read_count_all_barcodes.csv\",index=False)\n",
    "    return(sort_read_counts)\n",
    "    #print \"Total read length of all files is\", sum(sort_read_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_read_counts_total = []\n",
    "sample_list_total =  [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 27, 31, 32, 33, 34, 35]\n",
    "for Sample_index in sample_list_total:\n",
    "    sort_read_counts_total += [read_number_count(Sample_index, output_dirt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cutoff_list = [5000, 10000, 2000, 4000, 3500, 4000, 4000, 3500, 4000, 5000, 11000, 8000, 7000, 3000, 50000, 15000, 10000, 20000, 15000]\n",
    "max_cutoff_list = [40000, 75000, 20000, 25000, 20000, 40000, 40000, 40000, 30000, 30000, 80000, 100000, 75000, 40000, 400000, 250000, 80000, 200000, 90000]\n",
    "sample_list_total =  [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 27, 31, 32, 33, 34, 35]\n",
    "for sample_index in range(len(sample_list_total)):\n",
    "    print \"This is sample S\", sample_list_total[sample_index]\n",
    "    # this might be confusing, it is the index of a list, \n",
    "    #for example, sample_index 23, means 24th element in sort_read_counts_total\n",
    "    read_max = max_cutoff_list[sample_index]\n",
    "    read_min = min_cutoff_list[sample_index]\n",
    "    barcode_count = 0\n",
    "    read_count = 0\n",
    "    read_count_sample = pd.read_csv(base_dirt+'S'+\\\n",
    "                                    str(sample_list_total[sample_index])+\\\n",
    "                                    \"_read_count_all_barcodes.csv\")\n",
    "    for i in range(len(read_count_sample)):   \n",
    "        if read_count_sample['read_number'][i] > read_min:\n",
    "            barcode_count += 1\n",
    "            read_count += read_count_sample['read_number'][i]\n",
    "    print barcode_count, read_count, \\\n",
    "    read_count/(sum(read_count_sample['read_number']) + 0.0)\n",
    "\n",
    "    barcode_count = 0\n",
    "    read_count = 0\n",
    "    for i in range(len(read_count_sample)):   \n",
    "        if read_count_sample['read_number'][i] > read_max:\n",
    "            barcode_count += 1\n",
    "            read_count += read_count_sample['read_number'][i]\n",
    "    print barcode_count, read_count, \\\n",
    "    read_count/(sum(read_count_sample['read_number']) + 0.0)\n",
    "    keep_barcode_list = []\n",
    "    for i in range(len(read_count_sample['read_number'])):   \n",
    "        if read_count_sample['read_number'][i] < read_max and \\\n",
    "        read_count_sample['read_number'][i] > read_min:\n",
    "            keep_barcode_list.append(read_count_sample['barcode_list'][i])\n",
    "    print '{} cells are kept'.format(len(keep_barcode_list))\n",
    "    for i in keep_barcode_list:\n",
    "        dirt_temp_from= output_dirt + str(i) + '_R1.fastq'\n",
    "        dirt_temp_to= R1R2_filtered_dir_base + str(i) + '_R1.fastq'\n",
    "        shutil.move(dirt_temp_from, dirt_temp_to)\n",
    "        dirt_temp_from= output_dirt + str(i) + '_R2.fastq'\n",
    "        dirt_temp_to= R1R2_filtered_dir_base + str(i) + '_R2.fastq'\n",
    "        shutil.move(dirt_temp_from, dirt_temp_to)\n",
    "        if sample_list_total[sample_index] not in [6, 18,19,20,31, 32, 33, 34, 35]:\n",
    "            dirt_temp_from= output_dirt + str(i) + '_R2_nova.fastq'\n",
    "            dirt_temp_to= R1R2_filtered_dir_base + str(i) + '_R2_nova.fastq'\n",
    "            shutil.move(dirt_temp_from, dirt_temp_to)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Then at the filtered_selected folder, run \n",
    "### need to make sure folders \"../trimmed\" and \"../trimmed/log_files\" exist before the run\n",
    "for FILE_temp in *_R2.fastq; do\n",
    "echo ${FILE_temp};\n",
    "(java -jar {dirt to trimmomatic}/trimmomatic-0.36.jar PE -threads 12 -phred33 \\\n",
    "          -trimlog ../trimmed/log_files/${FILE_temp/_R2.fastq/}.log \\\n",
    "          ${FILE_temp/_R2.fastq/}_R1.fastq ${FILE_temp/_R2.fastq/}_R2.fastq \\\n",
    "          ../trimmed/${FILE_temp/_R2.fastq/}_R1_paired.fastq ../trimmed/${FILE_temp/_R2.fastq/}_R1_unpaired.fastq\\\n",
    "          ../trimmed/${FILE_temp/_R2.fastq/}_R2_paired.fastq ../trimmed/${FILE_temp/_R2.fastq/}_R2_unpaired.fastq\\\n",
    "          ILLUMINACLIP:{dirt to trimmomatic}/adapters/NexteraPE-PE.fa:2:30:10:3:TRUE \\\n",
    "          LEADING:25 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:30) \\\n",
    "        2> ../trimmed/log_files/${FILE_temp/_R2.fastq/}.trim.stderr.txt;\n",
    "done\n",
    "### The unpaired files are ingnored for the following analysis\n",
    "## Trim the Novaseq sequencing result by running\n",
    "for FILE in *_R2_nova.fastq; do\n",
    "echo ${FILE}\n",
    "(java -jar {dirt to trimmomatic}/trimmomatic-0.36.jar SE -threads 12 -phred33 \\\n",
    "          -trimlog ../trimmed/log_files/${FILE_temp/_R2_nova.fastq/}.log \\\n",
    "          ${FILE} \\\n",
    "          ../trimmed/${FILE/_R2_nova.fastq/}_R2_trimmed.fastq \\\n",
    "          ILLUMINACLIP:{dirt to trimmomatic}/adapters/NexteraPE-PE.fa:2:30:10 \\\n",
    "          LEADING:25 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:30) \\\n",
    "          2> ../trimmed/log_files/${FILE_temp/_R2.fastq/}.trim.stderr.txt;\n",
    "done\n",
    "\n",
    "\n",
    "### For sequencing files from the stool sample, \n",
    "###    1. Corresponding novaseq R2 files are trimmed\n",
    "###    2. The Novaseq R2 file, Nextseq R1 and R2 files are concatenated into a single file for following analysis"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
