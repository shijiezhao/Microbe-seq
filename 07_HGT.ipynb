{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.spatial.distance as sdist\n",
    "import umap\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, fcluster\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import math\n",
    "import os\n",
    "import random\n",
    "#import requests\n",
    "#from BeautifulSoup import BeautifulSoup\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from pylab import *\n",
    "#from ete3 import NCBITaxa\n",
    "#ncbi = NCBITaxa()\n",
    "import json\n",
    "from ast import literal_eval\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "strain_color_list = [\"#33bbff\",\"#0050e6\",\"#009999\", \"#777777\"]\n",
    "umap_plot_shape = ['D','o','s','v']\n",
    "default_color_list = [u'#1f77b4', u'#ff7f0e', u'#2ca02c', u'#d62728', u'#9467bd', u'#8c564b', u'#e377c2', u'#7f7f7f', u'#bcbd22', u'#17becf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function \n",
    "# input is query_cluster, qseqid, qstart and qend\n",
    "# output is to print out corresponding read\n",
    "def get_sequence(assembly_dirt, assembly_file_name, qseqid, qstart, qend):\n",
    "    with open(assembly_dirt + assembly_file_name) as finput:\n",
    "        while True:\n",
    "            line_read = finput.readline()  \n",
    "            if len (line_read) == 0:\n",
    "                break\n",
    "            if \">\" in line_read:\n",
    "                if qseqid in line_read:\n",
    "                    line_read = ''\n",
    "                    while True:\n",
    "                        line_read_temp = finput.readline().strip()\n",
    "                        line_read = line_read+line_read_temp\n",
    "                        if len (line_read) == 0 or \">\" in line_read:\n",
    "                            break\n",
    "                    string_of_mobile_gene = line_read.strip()[qstart-1:qend]\n",
    "                    #print len(string_of_mobile_gene),string_of_mobile_gene\n",
    "                    return string_of_mobile_gene\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to take intervals and return merged intervals\n",
    "def merge_intervals(intervals):\n",
    "    sorted_by_lower_bound = sorted(intervals, key=lambda tup: tup[0])\n",
    "    merged = []\n",
    "\n",
    "    for higher in sorted_by_lower_bound:\n",
    "        if not merged:\n",
    "            merged.append(higher)\n",
    "        else:\n",
    "            lower = merged[-1]\n",
    "            # test for intersection between lower and higher:\n",
    "            # we know via sorting that lower[0] <= higher[0]\n",
    "            if higher[0] <= lower[1]:\n",
    "                upper_bound = max(lower[1], higher[1])\n",
    "                merged[-1] = (lower[0], upper_bound)  # replace by merged interval\n",
    "            else:\n",
    "                merged.append(higher)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGT_strain_20210302_dirt = '/media/z/feb2021/microbe_seq_analysis/\\\n",
    "Q5_variant_calling_100fewer/strain_HGT_high_quality_20210302/'\n",
    "# this folder contains all the high-quality, strain-resovled genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#### this is to make database for all cleaned high quality genomes\n",
    "#### get name list\n",
    "file_list_of_assemblies = os.listdir(HGT_strain_20210302_dirt)\n",
    "for file_temp in file_list_of_assemblies:\n",
    "    if '.fna' not in file_temp:\n",
    "        file_list_of_assemblies.remove(file_temp)\n",
    "#%cd {HGT_strain_20210302_dirt}\n",
    "for file_temp in file_list_of_assemblies:\n",
    "    !makeblastdb -dbtype \"nucl\" -in {HGT_strain_20210302_dirt}{file_temp} \\\n",
    "    -out {HGT_strain_20210302_dirt}{file_temp[:-4]}_blastdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### this is to blast each against all other reference genomes\n",
    "for query_temp in file_list_of_assemblies:\n",
    "    for subject_temp in file_list_of_assemblies:\n",
    "        !blastn -query {HGT_strain_20210302_dirt}{query_temp} -db \\\n",
    "        {HGT_strain_20210302_dirt}{subject_temp[:-4]}_blastdb \\\n",
    "        -outfmt 6 -perc_identity 99.98 \\\n",
    "        -out {HGT_strain_20210302_dirt}{query_temp[:-4]}_to_{subject_temp[:-4]}_blast_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to read in all blastn result and put them in df\n",
    "\n",
    "# First get all file names\n",
    "file_list_of_assemblies = os.listdir(HGT_strain_20210302_dirt)\n",
    "a_temp_list = []\n",
    "blastn_HGT_result = []\n",
    "for i in range(len(file_list_of_assemblies)):\n",
    "    file_temp = file_list_of_assemblies[i]\n",
    "    if '_blast_result' not in file_temp:\n",
    "        continue\n",
    "    elif file_temp.split('to')[0][:-1] != \\\n",
    "    file_temp.split('to')[1][1:1+len(file_temp.split('to')[0][:-1])]:\n",
    "        a_temp_list += [file_temp]\n",
    "file_list_of_assemblies = a_temp_list\n",
    "print(len(file_list_of_assemblies))\n",
    "\n",
    "for file_temp in file_list_of_assemblies:\n",
    "    try:\n",
    "        temp_blastn_result = pd.read_csv(HGT_strain_20210302_dirt+file_temp,\\\n",
    "                                         header = None, sep = '\\t')\n",
    "    except:\n",
    "        #print file_temp, 'has no dection'\n",
    "        continue            \n",
    "    temp_blastn_result.columns = \\\n",
    "    ['qseqid', 'sseqid', 'pident', 'length', 'mismatch', \\\n",
    "     'gapopen', 'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore']\n",
    "    temp_blastn_result['query_cluster'] = [file_temp.split('to')[0][:-1]]*len(temp_blastn_result)\n",
    "    temp_blastn_result['subject_cluster'] = [file_temp.split('to')[1][1:-len('_blast_result')]]\\\n",
    "    *len(temp_blastn_result)\n",
    "    temp_blastn_result = temp_blastn_result.loc[temp_blastn_result['length']>500]\n",
    "    if len(blastn_HGT_result) > 0: # if not the first file, than cat dataframes\n",
    "        blastn_HGT_result = pd.concat([blastn_HGT_result, temp_blastn_result])\n",
    "    else:# if this is the first file with information, than apply the length to it\n",
    "        blastn_HGT_result = temp_blastn_result        \n",
    "blastn_HGT_result = blastn_HGT_result.sort_values(by=['query_cluster', 'subject_cluster',])\n",
    "blastn_HGT_result = blastn_HGT_result.reset_index(drop=True)\n",
    "cols = list(blastn_HGT_result.columns.values)\n",
    "blastn_HGT_result = blastn_HGT_result[cols[-2:-1] + cols[:1] + cols[-1:] + cols[1:2] + cols[2:-2]]\n",
    "blastn_HGT_result.to_csv(HGT_strain_20210302_dirt+'blastn_HGT_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_threshold = 5000\n",
    "match_bp_ratio = 99.98\n",
    "blastn_HGT_result = pd.read_csv(HGT_strain_20210302_dirt+'blastn_HGT_result.csv')\n",
    "blastn_result_sc = blastn_HGT_result.loc[blastn_HGT_result['length']>length_threshold].\\\n",
    "loc[blastn_HGT_result.loc[blastn_HGT_result['length']>length_threshold]['pident']>match_bp_ratio]\n",
    "blastn_result_sc = blastn_result_sc.reset_index(drop=True)\n",
    "blastn_result_sc.to_csv(HGT_strain_20210302_dirt+'blastn_HGT_result_trimmed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cluster_list = []\n",
    "subject_cluster_list = []\n",
    "total_length_of_HGT = []\n",
    "blastn_result_sc = pd.read_csv(HGT_strain_20210302_dirt+'blastn_HGT_result_trimmed.csv')\n",
    "assembly_all = list(set(list(set(blastn_result_sc['query_cluster']))+\\\n",
    "                        list(set(blastn_result_sc['subject_cluster']))))\n",
    "for query_temp in assembly_all:    \n",
    "    df_temp_query = blastn_result_sc.loc[blastn_result_sc['query_cluster']==query_temp]\n",
    "    for subject_temp in list(set(df_temp_query['subject_cluster'])):\n",
    "        df_temp_query_subject = df_temp_query.loc[df_temp_query['subject_cluster']==subject_temp]\n",
    "        df_temp_query_subject = df_temp_query_subject.reset_index(drop=True)\n",
    "        query_cluster_list += [query_temp]\n",
    "        subject_cluster_list += [subject_temp]\n",
    "        all_contig_list_temp = list(set(df_temp_query_subject['qseqid']))\n",
    "        total_HGT_count = 0\n",
    "        for i in range(len(all_contig_list_temp)):\n",
    "            contig_to_check_temp = all_contig_list_temp[i]\n",
    "            df_temp_query_subject_contig = df_temp_query_subject.loc\\\n",
    "            [df_temp_query_subject['qseqid']==contig_to_check_temp]\n",
    "            df_temp_query_subject_contig = df_temp_query_subject_contig.reset_index(drop=True)\n",
    "            all_intervals_temp = []\n",
    "            for j in range(len(df_temp_query_subject_contig)):\n",
    "                start_temp = min(df_temp_query_subject_contig['qstart'][j], df_temp_query_subject_contig['qend'][j])\n",
    "                end_temp = max(df_temp_query_subject_contig['qstart'][j], df_temp_query_subject_contig['qend'][j])\n",
    "                all_intervals_temp += [(start_temp,end_temp)]\n",
    "            merged_intervals_temp = merge_intervals(all_intervals_temp)\n",
    "            total_length_invervals = 0\n",
    "            for each_interval_temp in merged_intervals_temp:\n",
    "                total_length_invervals += each_interval_temp[1]-each_interval_temp[0] + 1\n",
    "            total_HGT_count += total_length_invervals\n",
    "        total_length_of_HGT += [total_HGT_count]\n",
    "blastn_result_sc_bp_count = pd.DataFrame({'query_cluster_list':query_cluster_list})\n",
    "blastn_result_sc_bp_count['subject_cluster_list'] = subject_cluster_list\n",
    "blastn_result_sc_bp_count['total_length_of_HGT'] = total_length_of_HGT\n",
    "blastn_result_sc_bp_count.to_csv(HGT_strain_20210302_dirt+'blastn_result_sc_bp_count.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
